{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261934, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('accounts_payable_v2_complete_adapted.csv')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261934 entries, 0 to 261933\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   company_seller_name  261934 non-null  object \n",
      " 1   doc_emission_date    261934 non-null  object \n",
      " 2   total_value          261934 non-null  float64\n",
      " 3   tag                  116569 non-null  object \n",
      " 4   category             261934 non-null  object \n",
      " 5   id_document          261934 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 12.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5571, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "to_stay = random.sample(dataset['category'].unique().tolist(), 8)\n",
    "dataset = dataset[dataset.category.isin(to_stay)]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_seller_name</th>\n",
       "      <th>doc_emission_date</th>\n",
       "      <th>total_value</th>\n",
       "      <th>tag</th>\n",
       "      <th>category</th>\n",
       "      <th>id_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>FEDERALEXPRESSCORPORATION</td>\n",
       "      <td>2014-11-20</td>\n",
       "      <td>7.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capital: Bldgs &amp; Bldg Equip</td>\n",
       "      <td>FT 000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>KWASSOCIATESINC</td>\n",
       "      <td>2014-11-26</td>\n",
       "      <td>54.70</td>\n",
       "      <td>Jantar Natal 2020</td>\n",
       "      <td>Printing &amp; Binding Fees</td>\n",
       "      <td>FT 000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>BOULDERCOUNTYFINANCIALSERVICES</td>\n",
       "      <td>2014-12-10</td>\n",
       "      <td>5.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Printing &amp; Binding Fees</td>\n",
       "      <td>FT 000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>BOULDERCOUNTYFINANCIALSERVICES</td>\n",
       "      <td>2014-12-10</td>\n",
       "      <td>9.98</td>\n",
       "      <td>Jantar Natal 2020</td>\n",
       "      <td>Printing &amp; Binding Fees</td>\n",
       "      <td>FT 000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>BOULDERCOUNTYFINANCIALSERVICES</td>\n",
       "      <td>2014-12-10</td>\n",
       "      <td>11.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Printing &amp; Binding Fees</td>\n",
       "      <td>FT 000207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                company_seller_name doc_emission_date  total_value  \\\n",
       "140       FEDERALEXPRESSCORPORATION        2014-11-20         7.14   \n",
       "156                 KWASSOCIATESINC        2014-11-26        54.70   \n",
       "204  BOULDERCOUNTYFINANCIALSERVICES        2014-12-10         5.63   \n",
       "206  BOULDERCOUNTYFINANCIALSERVICES        2014-12-10         9.98   \n",
       "207  BOULDERCOUNTYFINANCIALSERVICES        2014-12-10        11.15   \n",
       "\n",
       "                   tag                     category id_document  \n",
       "140                NaN  Capital: Bldgs & Bldg Equip   FT 000140  \n",
       "156  Jantar Natal 2020      Printing & Binding Fees   FT 000156  \n",
       "204                NaN      Printing & Binding Fees   FT 000204  \n",
       "206  Jantar Natal 2020      Printing & Binding Fees   FT 000206  \n",
       "207                NaN      Printing & Binding Fees   FT 000207  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['company_seller_name'] = dataset['company_seller_name'].apply(lambda c: c.replace(\" \",\"\"))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_seller_name</th>\n",
       "      <th>doc_emission_date</th>\n",
       "      <th>total_value</th>\n",
       "      <th>tag</th>\n",
       "      <th>category</th>\n",
       "      <th>id_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>FEDERALEXPRESSCORPORATION</td>\n",
       "      <td>1.416442e+09</td>\n",
       "      <td>7.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capital: Bldgs &amp; Bldg Equip</td>\n",
       "      <td>FT 000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>KWASSOCIATESINC</td>\n",
       "      <td>1.416960e+09</td>\n",
       "      <td>54.70</td>\n",
       "      <td>Jantar Natal 2020</td>\n",
       "      <td>Printing &amp; Binding Fees</td>\n",
       "      <td>FT 000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>BOULDERCOUNTYFINANCIALSERVICES</td>\n",
       "      <td>1.418170e+09</td>\n",
       "      <td>5.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Printing &amp; Binding Fees</td>\n",
       "      <td>FT 000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>BOULDERCOUNTYFINANCIALSERVICES</td>\n",
       "      <td>1.418170e+09</td>\n",
       "      <td>9.98</td>\n",
       "      <td>Jantar Natal 2020</td>\n",
       "      <td>Printing &amp; Binding Fees</td>\n",
       "      <td>FT 000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>BOULDERCOUNTYFINANCIALSERVICES</td>\n",
       "      <td>1.418170e+09</td>\n",
       "      <td>11.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Printing &amp; Binding Fees</td>\n",
       "      <td>FT 000207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                company_seller_name  doc_emission_date  total_value  \\\n",
       "140       FEDERALEXPRESSCORPORATION       1.416442e+09         7.14   \n",
       "156                 KWASSOCIATESINC       1.416960e+09        54.70   \n",
       "204  BOULDERCOUNTYFINANCIALSERVICES       1.418170e+09         5.63   \n",
       "206  BOULDERCOUNTYFINANCIALSERVICES       1.418170e+09         9.98   \n",
       "207  BOULDERCOUNTYFINANCIALSERVICES       1.418170e+09        11.15   \n",
       "\n",
       "                   tag                     category id_document  \n",
       "140                NaN  Capital: Bldgs & Bldg Equip   FT 000140  \n",
       "156  Jantar Natal 2020      Printing & Binding Fees   FT 000156  \n",
       "204                NaN      Printing & Binding Fees   FT 000204  \n",
       "206  Jantar Natal 2020      Printing & Binding Fees   FT 000206  \n",
       "207                NaN      Printing & Binding Fees   FT 000207  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['doc_emission_date'] = pd.to_datetime(dataset['doc_emission_date']).astype(int)/ 10**9\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3163, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_seller_name</th>\n",
       "      <th>doc_emission_date</th>\n",
       "      <th>total_value</th>\n",
       "      <th>tag</th>\n",
       "      <th>category</th>\n",
       "      <th>id_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>TOSHIBAAMERICABUSINESSSOLUTIONS,INC</td>\n",
       "      <td>1.419293e+09</td>\n",
       "      <td>100.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Copy Charges and Supplies</td>\n",
       "      <td>FT 000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>TOSHIBAAMERICABUSINESSSOLUTIONS,INC</td>\n",
       "      <td>1.419725e+09</td>\n",
       "      <td>235.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Copy Charges and Supplies</td>\n",
       "      <td>FT 000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>CANONSOLUTIONSAMERICA,INC</td>\n",
       "      <td>1.419984e+09</td>\n",
       "      <td>185.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Copy Charges and Supplies</td>\n",
       "      <td>FT 000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>LEWAN&amp;ASSOCIATESINC</td>\n",
       "      <td>1.420070e+09</td>\n",
       "      <td>82.75</td>\n",
       "      <td>Despesas Com1</td>\n",
       "      <td>Copy Charges and Supplies</td>\n",
       "      <td>FT 000417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>LEWAN&amp;ASSOCIATESINC</td>\n",
       "      <td>1.420070e+09</td>\n",
       "      <td>82.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Copy Charges and Supplies</td>\n",
       "      <td>FT 000420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company_seller_name  doc_emission_date  total_value  \\\n",
       "286  TOSHIBAAMERICABUSINESSSOLUTIONS,INC       1.419293e+09       100.51   \n",
       "333  TOSHIBAAMERICABUSINESSSOLUTIONS,INC       1.419725e+09       235.14   \n",
       "387            CANONSOLUTIONSAMERICA,INC       1.419984e+09       185.72   \n",
       "417                  LEWAN&ASSOCIATESINC       1.420070e+09        82.75   \n",
       "420                  LEWAN&ASSOCIATESINC       1.420070e+09        82.75   \n",
       "\n",
       "               tag                   category id_document  \n",
       "286            NaN  Copy Charges and Supplies   FT 000286  \n",
       "333            NaN  Copy Charges and Supplies   FT 000333  \n",
       "387            NaN  Copy Charges and Supplies   FT 000387  \n",
       "417  Despesas Com1  Copy Charges and Supplies   FT 000417  \n",
       "420            NaN  Copy Charges and Supplies   FT 000420  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words='english')\n",
    "X1 = tfidfconverter.fit_transform(dataset['company_seller_name']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3163, 47)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X1)\n",
    "X['value'] = dataset['total_value'].values\n",
    "X['date'] = dataset['doc_emission_date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.51</td>\n",
       "      <td>1.419293e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235.14</td>\n",
       "      <td>1.419725e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.72</td>\n",
       "      <td>1.419984e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.75</td>\n",
       "      <td>1.420070e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.75</td>\n",
       "      <td>1.420070e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7         8    9  ...   39   40   41  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  ...  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.707107  0.0  ...  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.707107  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    42   43   44   45   46   value          date  \n",
       "0  0.0  0.0  1.0  0.0  0.0  100.51  1.419293e+09  \n",
       "1  0.0  0.0  1.0  0.0  0.0  235.14  1.419725e+09  \n",
       "2  0.0  0.0  0.0  0.0  0.0  185.72  1.419984e+09  \n",
       "3  0.0  0.0  0.0  0.0  0.0   82.75  1.420070e+09  \n",
       "4  0.0  0.0  0.0  0.0  0.0   82.75  1.420070e+09  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_seller_name</th>\n",
       "      <th>doc_emission_date</th>\n",
       "      <th>total_value</th>\n",
       "      <th>tag</th>\n",
       "      <th>category</th>\n",
       "      <th>id_document</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>TOSHIBAAMERICABUSINESSSOLUTIONS,INC</td>\n",
       "      <td>1.419293e+09</td>\n",
       "      <td>100.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Copy Charges and Supplies</td>\n",
       "      <td>FT 000286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>TOSHIBAAMERICABUSINESSSOLUTIONS,INC</td>\n",
       "      <td>1.419725e+09</td>\n",
       "      <td>235.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Copy Charges and Supplies</td>\n",
       "      <td>FT 000333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>CANONSOLUTIONSAMERICA,INC</td>\n",
       "      <td>1.419984e+09</td>\n",
       "      <td>185.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Copy Charges and Supplies</td>\n",
       "      <td>FT 000387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>LEWAN&amp;ASSOCIATESINC</td>\n",
       "      <td>1.420070e+09</td>\n",
       "      <td>82.75</td>\n",
       "      <td>Despesas Com1</td>\n",
       "      <td>Copy Charges and Supplies</td>\n",
       "      <td>FT 000417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>LEWAN&amp;ASSOCIATESINC</td>\n",
       "      <td>1.420070e+09</td>\n",
       "      <td>82.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Copy Charges and Supplies</td>\n",
       "      <td>FT 000420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company_seller_name  doc_emission_date  total_value  \\\n",
       "286  TOSHIBAAMERICABUSINESSSOLUTIONS,INC       1.419293e+09       100.51   \n",
       "333  TOSHIBAAMERICABUSINESSSOLUTIONS,INC       1.419725e+09       235.14   \n",
       "387            CANONSOLUTIONSAMERICA,INC       1.419984e+09       185.72   \n",
       "417                  LEWAN&ASSOCIATESINC       1.420070e+09        82.75   \n",
       "420                  LEWAN&ASSOCIATESINC       1.420070e+09        82.75   \n",
       "\n",
       "               tag                   category id_document  category_id  \n",
       "286            NaN  Copy Charges and Supplies   FT 000286            1  \n",
       "333            NaN  Copy Charges and Supplies   FT 000333            1  \n",
       "387            NaN  Copy Charges and Supplies   FT 000387            1  \n",
       "417  Despesas Com1  Copy Charges and Supplies   FT 000417            1  \n",
       "420            NaN  Copy Charges and Supplies   FT 000420            1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['category'] = dataset['category'].astype('category')\n",
    "dataset[\"category_id\"] = dataset[\"category\"].cat.codes\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dataset['category_id'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=len(dataset['category_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=8)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.32      0.18      0.23       101\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.82      0.92      0.87      1483\n",
      "           4       0.14      0.06      0.08       109\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.64      0.59      0.62       651\n",
      "           7       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.75      2366\n",
      "   macro avg       0.24      0.22      0.22      2366\n",
      "weighted avg       0.71      0.75      0.73      2366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "#print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pimonteiro/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7268011527377523\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "{'criterion': 'entropy', 'n_estimators': 100}\n",
      "       company_seller_name  doc_emission_date  total_value            tag  \\\n",
      "76  KLEEN-TECHSERVICESCORP       1.412035e+09      3773.79  Despesas Com2   \n",
      "\n",
      "                         category id_document  category_id  \n",
      "76  Janitorial and Custodial Svcs   FT 000076          152  \n",
      "   0    1    2    3    4    5    6    7    8    9    ...  98   99   100  101  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
      "\n",
      "   102  103  104  105  106  107  \n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[1 rows x 108 columns]\n",
      "[152]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "random.seed = 0\n",
    "\n",
    "dataset = pd.read_csv('accounts_payable_v2_complete_adapted.csv')\n",
    "dataset['company_seller_name'] = dataset['company_seller_name'].apply(lambda c: c.replace(\" \",\"\"))\n",
    "dataset['doc_emission_date'] = pd.to_datetime(dataset['doc_emission_date']).astype(int)/ 10**9\n",
    "dataset['category'] = dataset['category'].astype('category')\n",
    "dataset[\"category_id\"] = dataset[\"category\"].cat.codes\n",
    "\n",
    "to_stay = random.sample(dataset['category'].unique().tolist(), 8)\n",
    "new_dataset = dataset[dataset.category.isin(to_stay)]\n",
    "\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words='english')\n",
    "X1 = tfidfconverter.fit_transform(new_dataset['company_seller_name']).toarray()\n",
    "X = pd.DataFrame(X1)\n",
    "X['value'] = new_dataset['total_value'].values\n",
    "X['date'] = new_dataset['doc_emission_date'].values\n",
    "\n",
    "results = rndforest_gridsearch(X, new_dataset['category_id'])\n",
    "\n",
    "model = results.best_estimator_\n",
    "\n",
    "tmp = new_dataset.head(1)\n",
    "print(tmp)\n",
    "\n",
    "n_d = pd.DataFrame(tfidfconverter.transform(tmp['company_seller_name']).toarray())\n",
    "print(n_d.head())\n",
    "n_d['value'] = tmp['total_value'].values\n",
    "n_d['date'] = tmp['doc_emission_date'].values\n",
    "\n",
    "cat = model.predict(n_d)\n",
    "print(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = dataset['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def kneares_gridsearch(X_train, y_train):\n",
    "    params = {\n",
    "        'n_neighbors': [3,5,1,19],\n",
    "        'weights': ['uniform','distance'],\n",
    "        'metric': ['euclidean','manhattan'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(KNeighborsClassifier(), params, cv=3, n_jobs=-1, verbose=1)\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "    print(gs_results.best_score_)\n",
    "    print(gs_results.best_estimator_)\n",
    "    print(gs_results.best_params_)\n",
    "    \n",
    "def svc_gridsearch(X_train, y_train):\n",
    "    params = {\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'C':[0.1, 1, 10],\n",
    "        'gamma': ['auto'],\n",
    "        'probability': [False]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(SVC(), params, cv=3, n_jobs=-1, verbose=1)\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "    print(gs_results.best_score_)\n",
    "    print(gs_results.best_estimator_)\n",
    "    print(gs_results.best_params_)\n",
    "\n",
    "def rndforest_gridsearch(X_train, y_train):\n",
    "    params = {\n",
    "        'n_estimators': [10, 100],\n",
    "        'criterion': ['gini','entropy']\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(RandomForestClassifier(), params, cv=3, n_jobs=-1, verbose=1)\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "    print(gs_results.best_score_)\n",
    "    print(gs_results.best_estimator_)\n",
    "    print(gs_results.best_params_)\n",
    "    return gs_results\n",
    "    \n",
    "def gradb_gridsearch(X_train, y_train):\n",
    "    params = {\n",
    "        'n_estimators': ['deviance', 'exponential'],\n",
    "        'criterion': ['friedman_mse', 'mse'],\n",
    "        'learning_rate': [0.01, 0.1, 1],\n",
    "        'n_estimators': [10, 100]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(GradientBoostingClassifier(), params, cv=3, n_jobs=-1, verbose=1)\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "    print(gs_results.best_score_)\n",
    "    print(gs_results.best_estimator_)\n",
    "    print(gs_results.best_params_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pimonteiro/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21974183955802165\n",
      "KNeighborsClassifier(metric='euclidean', n_neighbors=19)\n",
      "{'algorithm': 'auto', 'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'uniform'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:   11.3s finished\n"
     ]
    }
   ],
   "source": [
    "kneares_gridsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-9d1b396f2552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvc_gridsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-125-3c1976bb79e3>\u001b[0m in \u001b[0;36msvc_gridsearch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mgs_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/ml-data-analytics/env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/ml-data-analytics/env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/ml-data-analytics/env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svc_gridsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pimonteiro/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "0.8801460471055874\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "{'criterion': 'gini', 'n_estimators': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "rndforest_gridsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dataset['category_id'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 29   0   0   0   0   0]\n",
      " [  0 416   2   0   0   0]\n",
      " [  0   1 174   0   0   0]\n",
      " [  0   0   0   5   0   0]\n",
      " [  0   0   0   0   4   0]\n",
      " [  0   0   0   0   0   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        29\n",
      "           1       1.00      1.00      1.00       418\n",
      "           2       0.99      0.99      0.99       175\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       633\n",
      "   macro avg       1.00      1.00      1.00       633\n",
      "weighted avg       1.00      1.00      1.00       633\n",
      "\n",
      "0.995260663507109\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(criterion='gini', n_estimators=10)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_model(epochs):\n",
    "    dataset = pd.read_csv('accounts_payable_v2_complete_adapted.csv')\n",
    "    dataset['company_seller_name'] = dataset['company_seller_name'].apply(lambda c: c.replace(\" \",\"\"))\n",
    "    dataset['doc_emission_date'] = pd.to_datetime(dataset['doc_emission_date']).astype(int)/ 10**9\n",
    "    dataset['category'] = dataset['category'].astype('category')\n",
    "    dataset[\"category_id\"] = dataset[\"category\"].cat.codes\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        to_stay = random.sample(dataset['category'].unique().tolist(), 8)\n",
    "        new_dataset = dataset[dataset.category.isin(to_stay)]\n",
    "        \n",
    "        tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words='english')\n",
    "        X1 = tfidfconverter.fit_transform(new_dataset['company_seller_name']).toarray()\n",
    "        X = pd.DataFrame(X1)\n",
    "        X['value'] = new_dataset['total_value'].values\n",
    "        X['date'] = new_dataset['doc_emission_date'].values\n",
    "        \n",
    "        print(\"=====Iteration \",i,\"=====\")\n",
    "        rndforest_gridsearch(X, new_dataset['category_id'])\n",
    "        #kneares_gridsearch(X, new_dataset['category_id'])\n",
    "        gradb_gridsearch(X, new_dataset['category_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pimonteiro/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   34.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9897234731147129\n",
      "GradientBoostingClassifier()\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "gradb_gridsearch(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Iteration  0 =====\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pimonteiro/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.583735781720015\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "{'criterion': 'entropy', 'n_estimators': 10}\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pimonteiro/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333586433323135\n",
      "GradientBoostingClassifier(learning_rate=0.01, n_estimators=10)\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'n_estimators': 10}\n",
      "=====Iteration  1 =====\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6316618535048569\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "{'criterion': 'entropy', 'n_estimators': 100}\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7198739826726174\n",
      "GradientBoostingClassifier(learning_rate=0.01, n_estimators=10)\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.01, 'n_estimators': 10}\n",
      "=====Iteration  2 =====\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9974593495934959\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "{'criterion': 'entropy', 'n_estimators': 100}\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   31.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949186991869919\n",
      "GradientBoostingClassifier()\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "=====Iteration  3 =====\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pimonteiro/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6708742402992053\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "{'criterion': 'entropy', 'n_estimators': 100}\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pimonteiro/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5935016362786348\n",
      "GradientBoostingClassifier(criterion='mse', learning_rate=0.01, n_estimators=10)\n",
      "{'criterion': 'mse', 'learning_rate': 0.01, 'n_estimators': 10}\n",
      "=====Iteration  4 =====\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pimonteiro/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972326569136385\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "{'criterion': 'entropy', 'n_estimators': 100}\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pimonteiro/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   15.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9549189869435267\n",
      "GradientBoostingClassifier(criterion='mse')\n",
      "{'criterion': 'mse', 'learning_rate': 0.1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "test_best_model(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-299842d881e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train, verbose=1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pimonteiro/repos/ml-data-analytics/env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    5.8s finished\n"
     ]
    }
   ],
   "source": [
    "results = rndforest_gridsearch(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "final = results.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-06 19:30:16.793971\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "expiration = datetime.now() + timedelta(days = 15)\n",
    "print(expiration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nif</th>\n",
       "      <th>company_seller_name</th>\n",
       "      <th>total_value</th>\n",
       "      <th>doc_emission_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234</td>\n",
       "      <td>Razoes para Adultos</td>\n",
       "      <td>130</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234</td>\n",
       "      <td>Razoes para Adultos</td>\n",
       "      <td>130</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nif  company_seller_name  total_value doc_emission_date\n",
       "0  1234  Razoes para Adultos          130        2020-12-22\n",
       "1  1234  Razoes para Adultos          130        2020-12-22"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = \"{\\\"0\\\":{\\\"nif\\\":\\\"1234\\\",\\\"company_seller_name\\\":\\\"Razoes para Adultos\\\",\\\"total_value\\\":130,\\\"doc_emission_date\\\":\\\"2020-12-22\\\"},\\\"1\\\":{\\\"nif\\\":\\\"1234\\\",\\\"company_seller_name\\\":\\\"Razoes para Adultos\\\",\\\"total_value\\\":130,\\\"doc_emission_date\\\":\\\"2020-12-22\\\"}}\"\n",
    "ttt = pd.read_json(tr, orient='index')\n",
    "ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ttt['nif'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2 entries, 0 to 1\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   nif                  2 non-null      object\n",
      " 1   company_seller_name  2 non-null      object\n",
      " 2   total_value          2 non-null      int64 \n",
      " 3   doc_emission_date    2 non-null      object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 80.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "ttt['nif'] = ttt.nif.astype(str)\n",
    "ttt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 130, 1: 130}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "categories = [130, 130]\n",
    "for i in range(len(categories)):\n",
    "    results[i] = categories[i]\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\": {\"nif\": \"1234\", \"company_seller_name\": \"Razoes para Adultos\", \"total_value\": 130, \"doc_emission_date\": \"2020-12-22\"}, \"1\": {\"nif\": \"1234\", \"company_seller_name\": \"Razoes para Adultos\", \"total_value\": 130, \"doc_emission_date\": \"2020-12-22\"}}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "p = {\n",
    "    \"0\": {\n",
    "     \"nif\":\"1234\",\n",
    "     \"company_seller_name\":\"Razoes para Adultos\",\n",
    "     \"total_value\":130,\n",
    "     \"doc_emission_date\": \"2020-12-22\"\n",
    "    },\n",
    "        \"1\": {\n",
    "     \"nif\":\"1234\",\n",
    "     \"company_seller_name\":\"Razoes para Adultos\",\n",
    "     \"total_value\":130,\n",
    "     \"doc_emission_date\": \"2020-12-22\"\n",
    "    }\n",
    "}\n",
    "\n",
    "json.dumps(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
